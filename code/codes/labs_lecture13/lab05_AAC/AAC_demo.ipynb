{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 05 : Advantageous Actor-Critic (AAC) - demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(torch.randint(10000,())) # random seed for pythorch random generator\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import gym\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from itertools import count\n",
    "\n",
    "class DotDict(dict):\n",
    "    def __init__(self, **kwds):\n",
    "        self.update(kwds)\n",
    "        self.__dict__ = self\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init state: [ 0.03073904  0.00145001 -0.03088818 -0.03131252]\n",
      "t= 0 action= 1 state= [ 0.03077  0.197   -0.03151 -0.33358] reward= 1.0 done= False\n",
      "t= 1 action= 1 state= [ 0.03471  0.39256 -0.03819 -0.63603] reward= 1.0 done= False\n",
      "t= 2 action= 1 state= [ 0.04256  0.58819 -0.05091 -0.94049] reward= 1.0 done= False\n",
      "t= 3 action= 1 state= [ 0.05432  0.78396 -0.06972 -1.24872] reward= 1.0 done= False\n",
      "t= 4 action= 1 state= [ 0.07     0.9799  -0.09469 -1.56241] reward= 1.0 done= False\n",
      "t= 5 action= 0 state= [ 0.0896   0.78603 -0.12594 -1.3007 ] reward= 1.0 done= False\n",
      "t= 6 action= 0 state= [ 0.10532  0.59271 -0.15195 -1.04995] reward= 1.0 done= False\n",
      "t= 7 action= 1 state= [ 0.11718  0.78949 -0.17295 -1.38621] reward= 1.0 done= False\n",
      "t= 8 action= 0 state= [ 0.13296  0.59689 -0.20068 -1.15222] reward= 1.0 done= False\n",
      "t= 9 action= 1 state= [ 0.1449   0.79398 -0.22372 -1.50053] reward= 1.0 done= True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Env parameters\n",
    "env_seed = 1\n",
    "render = True # display on\n",
    "render = False # display off\n",
    "\n",
    "#Initialize the environment with the same seed/initialization value\n",
    "env = gym.make('CartPole-v0')\n",
    "env.seed(env_seed)\n",
    "\n",
    "#Reset the environment\n",
    "state = env.reset() \n",
    "print('init state:',state)\n",
    "\n",
    "#Rollout one episode until it finishes \n",
    "for t in count():  \n",
    "    action = torch.LongTensor(1).random_(0,2).item() # randomly generated action=a in {0,1}\n",
    "    state, reward, done, _ = env.step(action) # receive next state=s' and reward=r\n",
    "    print('t=',t, 'action=',action, 'state=',np.array_str(state, precision=5), 'reward=',reward, 'done=',done )\n",
    "    if render:\n",
    "        env.render() # see the state\n",
    "    if done:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the policy network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActorCritic_NN(\n",
      "  (fc1_p): Linear(in_features=4, out_features=128, bias=True)\n",
      "  (fc2_p): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (fc1_q_a): Linear(in_features=4, out_features=128, bias=True)\n",
      "  (fc2_q_a): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (fc1_q_s): Linear(in_features=4, out_features=128, bias=True)\n",
      "  (fc2_q_s): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "batch_episode_lengths: [8, 45, 12]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# class of policy network\n",
    "class ActorCritic_NN(nn.Module): \n",
    "    \n",
    "    def __init__(self, net_parameters):\n",
    "        super(ActorCritic_NN, self).__init__()\n",
    "        input_dim = net_parameters['input_dim']\n",
    "        hidden_dim = net_parameters['hidden_dim']\n",
    "        output_dim = net_parameters['output_dim']\n",
    "        # policy network\n",
    "        self.fc1_p = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2_p = nn.Linear(hidden_dim, output_dim)\n",
    "        # action-value function network\n",
    "        self.fc1_q_a = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2_q_a = nn.Linear(hidden_dim, output_dim)\n",
    "        # state-value function network\n",
    "        self.fc1_q_s = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2_q_s = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward_policy(self, x):\n",
    "        x = torch.relu(self.fc1_p(x))\n",
    "        actions_score = self.fc2_p(x)\n",
    "        actions_prob = torch.softmax(actions_score, dim=1)\n",
    "        return actions_prob\n",
    "    \n",
    "    def forward_Q_a(self, x):\n",
    "        x = torch.relu(self.fc1_q_a(x))\n",
    "        Q_scores = self.fc2_q_a(x) # scores over actions \n",
    "        return Q_scores\n",
    "    \n",
    "    def forward_Q_s(self, x):\n",
    "        x = torch.relu(self.fc1_q_s(x))\n",
    "        Q_scores = self.fc2_q_s(x) # scores over actions \n",
    "        return Q_scores\n",
    "    \n",
    "    def select_action(self, state): # select action w/ policy network\n",
    "        probs = self.forward_policy(state) # probability of action a in state s\n",
    "        bernoulli_sampling = torch.distributions.Categorical(probs) \n",
    "        action = bernoulli_sampling.sample() # sample action a with Bernoulli sampling\n",
    "        return action\n",
    "\n",
    "    def loss(self, batch):\n",
    "        gamma = opt_parameters['gamma']\n",
    "        nb_episodes_per_batch = len(batch.states)\n",
    "        batch_losses = []\n",
    "        for episode in range(nb_episodes_per_batch):\n",
    "            episode_states = torch.stack( batch.states[episode] ).float() #size=B x 4     \n",
    "            episode_next_states = torch.stack( batch.next_states[episode] ).float() #size=B x 4  \n",
    "            episode_actions = torch.stack( batch.actions[episode] ).long() #size=B\n",
    "            episode_rewards = - torch.stack( batch.rewards[episode] ).float() #size=B\n",
    "            episode_dones = torch.stack( batch.dones[episode] ).float() #size=B\n",
    "            R = 0; policy_loss = []; rewards = []\n",
    "            for r in batch.rewards[episode][::-1]: # compute the discarded award at each time step\n",
    "                R = r + gamma * R\n",
    "                rewards.insert(0, R)\n",
    "            episode_discounted_rewards = torch.tensor(rewards).float() #size=B\n",
    "            episode_next_actions = self.select_action(episode_next_states) #size=B\n",
    "            Q = self.forward_Q_a(episode_states).gather(dim=1,index=episode_actions.unsqueeze(1)) # Qv(a|s), size=B x 1\n",
    "            Q_target = episode_rewards.unsqueeze(1) + gamma *  \\\n",
    "                self.forward_Q_a(episode_next_states).gather(dim=1,index=episode_next_actions.unsqueeze(1)) * episode_dones.unsqueeze(1)\n",
    "            Q_state = self.forward_Q_s(episode_states)\n",
    "            logP = torch.log( actorcritic_net.forward_policy(episode_states).gather(dim=1,index=episode_actions.unsqueeze(1)) )\n",
    "            loss1 = ( -logP * (Q-Q_state).detach() ).mean()\n",
    "            loss2 = nn.MSELoss()(Q,Q_target.detach())\n",
    "            loss3 = nn.MSELoss()(Q_state,episode_discounted_rewards.unsqueeze(1).detach())\n",
    "            loss = loss1 + loss2 + loss3\n",
    "            batch_losses.append(loss)\n",
    "        loss = torch.stack(batch_losses).mean()\n",
    "        return loss\n",
    "\n",
    "        \n",
    "# class of rollout episodes\n",
    "class Rollout_Episodes():\n",
    "    \n",
    "    def __init__(self,):\n",
    "        super(Rollout_Episodes, self).__init__()\n",
    "    \n",
    "    def rollout_batch_episodes(self, env, opt_parameters, actorcritic_net, write_memory=True):\n",
    "        # storage structure of all episodes (w/ different lengths)\n",
    "        nb_episodes_per_batch = opt_parameters['nb_episodes_per_batch']\n",
    "        env_seeds = opt_parameters['env_seed']\n",
    "        batch = DotDict()\n",
    "        batch.states=[];  batch.actions=[]; batch.next_states=[]; batch.rewards=[]; batch.dones=[]\n",
    "        batch_episode_lengths = []\n",
    "        for episode in range(nb_episodes_per_batch):\n",
    "            states=[]; actions=[]; next_states=[]; rewards=[]; dones = []\n",
    "            env.seed(env_seeds[episode].item()) # start with random seed\n",
    "            state = env.reset() # reset environment\n",
    "            for t in range(1000): # rollout one episode \n",
    "                state_pytorch = torch.from_numpy(state).float().unsqueeze(0) # state=s\n",
    "                action = actorcritic_net.select_action(state_pytorch).item() # select action=a from state=s\n",
    "                next_state, reward, done, _ = env.step(action) # receive next state=s' and reward=r\n",
    "                done_mask = 0.0 if done else 1.0\n",
    "                states.append(torch.tensor(state))\n",
    "                actions.append(torch.tensor(action))\n",
    "                next_states.append(torch.tensor(next_state))\n",
    "                rewards.append(torch.tensor(reward))\n",
    "                dones.append(torch.tensor(done_mask))\n",
    "                state = next_state\n",
    "                if done:\n",
    "                    batch_episode_lengths.append(t)\n",
    "                    break\n",
    "            batch.states.append(states)\n",
    "            batch.actions.append(actions)\n",
    "            batch.next_states.append(next_states)\n",
    "            batch.rewards.append(rewards)\n",
    "            batch.dones.append(dones)\n",
    "        return batch_episode_lengths, batch\n",
    "\n",
    "        \n",
    "    \n",
    "# network parameters\n",
    "net_parameters = {}\n",
    "net_parameters['input_dim'] = 4\n",
    "net_parameters['hidden_dim'] = 128\n",
    "net_parameters['output_dim'] = 2\n",
    "\n",
    "# instantiate network\n",
    "actorcritic_net = ActorCritic_NN(net_parameters)\n",
    "print(actorcritic_net)\n",
    "\n",
    "# instantiate rollout\n",
    "rollout_policy_net = Rollout_Episodes()\n",
    "\n",
    "# optimization parameters\n",
    "opt_parameters = {}\n",
    "opt_parameters['nb_episodes_per_batch'] = 3\n",
    "opt_parameters['env_seed'] = torch.LongTensor(opt_parameters['nb_episodes_per_batch']).random_(1,10000)\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "batch_episode_lengths, batch = rollout_policy_net.rollout_batch_episodes(env, opt_parameters, actorcritic_net)\n",
    "#print('batch:',batch)\n",
    "print('batch_episode_lengths:',batch_episode_lengths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_episode_lengths: [19, 26, 13]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# optimization parameters\n",
    "opt_parameters = {}\n",
    "opt_parameters['lr'] = 0.001\n",
    "opt_parameters['nb_episodes_per_batch'] = 3\n",
    "opt_parameters['env_seed'] = torch.LongTensor(opt_parameters['nb_episodes_per_batch']).random_(1,10000)\n",
    "opt_parameters['gamma'] = 0.99\n",
    "\n",
    "batch_episode_lengths, batch = rollout_policy_net.rollout_batch_episodes(env, opt_parameters, actorcritic_net)\n",
    "#print('batch:',batch)\n",
    "print('batch_episode_lengths:',batch_episode_lengths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(132.1139, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loss\n",
    "loss = actorcritic_net.loss(batch)\n",
    "print('loss:',loss)\n",
    "\n",
    "# Backward pass\n",
    "lr = opt_parameters['lr']\n",
    "optimizer = torch.optim.Adam(actorcritic_net.parameters(), lr=lr)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch(env, actorcritic_net, opt_parameters):\n",
    "    \"\"\"\n",
    "    train one epoch\n",
    "    \"\"\"\n",
    "    actorcritic_net.train()\n",
    "    epoch_loss = 0\n",
    "    nb_data = 0\n",
    "    epoch_episode_length = 0\n",
    "    epoch_episode_lengths = []\n",
    "    nb_batches_per_epoch = opt_parameters['nb_batches_per_epoch']\n",
    "    for iter in range(nb_batches_per_epoch):\n",
    "        batch_episode_lengths, batch = \\\n",
    "            rollout_policy_net.rollout_batch_episodes(env, opt_parameters, actorcritic_net)\n",
    "        loss = actorcritic_net.loss(batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.detach().item()\n",
    "        nb_data += len(batch_episode_lengths)\n",
    "        epoch_episode_length += torch.tensor(batch_episode_lengths).float().sum()\n",
    "        epoch_episode_lengths.append(epoch_episode_length)\n",
    "    epoch_loss /= nb_data\n",
    "    epoch_episode_length /= nb_data\n",
    "    return epoch_loss, epoch_episode_length, epoch_episode_lengths\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done.\n",
      "Last episode length is 391.82000732421875, epoch is 44\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# network parameters\n",
    "net_parameters = {}\n",
    "net_parameters['input_dim'] = 4\n",
    "net_parameters['hidden_dim'] = 256\n",
    "net_parameters['output_dim'] = 2\n",
    "\n",
    "# instantiate network\n",
    "actorcritic_net = ActorCritic_NN(net_parameters)\n",
    "print(actorcritic_net)\n",
    "\n",
    "# optimization parameters\n",
    "opt_parameters = {}\n",
    "opt_parameters['lr'] = 0.0005\n",
    "opt_parameters['nb_episodes_per_batch'] = 1\n",
    "opt_parameters['nb_batches_per_epoch'] = 50\n",
    "opt_parameters['env_seed'] = torch.LongTensor(opt_parameters['nb_episodes_per_batch']).random_(1,10000)\n",
    "opt_parameters['gamma'] = 0.99\n",
    "\n",
    "optimizer = torch.optim.Adam(actorcritic_net.parameters(), lr=opt_parameters['lr'] )\n",
    "\n",
    "# select maximum episode length to learn\n",
    "env = gym.make('CartPole-v0')\n",
    "env._max_episode_steps = 400 # 200 400\n",
    "env.spec.reward_threshold = 0.975* env._max_episode_steps\n",
    "print('env._max_episode_steps',env._max_episode_steps)\n",
    "\n",
    "# train loop\n",
    "all_epoch_lengths = []\n",
    "start = time.time()\n",
    "for epoch in range(500): \n",
    "    \n",
    "    # train one epoch\n",
    "    epoch_train_loss, epoch_episode_length, epoch_episode_lengths = train_one_epoch(env, actorcritic_net, opt_parameters)\n",
    " \n",
    "    # stop training when reward is high\n",
    "    if epoch_episode_length > env.spec.reward_threshold:\n",
    "        print('Training done.')\n",
    "        print(\"Last episode length is {}, epoch is {}\".\n",
    "              format(epoch_episode_length, epoch))\n",
    "        break\n",
    "\n",
    "    # print intermediate info\n",
    "    if not epoch%1:\n",
    "        print('Epoch: {}, time: {:.4f}, train_loss: {:.4f}, episode_length: {:.4f}'.format(epoch, time.time()-start, epoch_train_loss, epoch_episode_length))\n",
    "        \n",
    "    # plot all epochs\n",
    "    all_epoch_lengths.append(epoch_episode_length)\n",
    "    if not epoch%1:\n",
    "        plt.figure(2)\n",
    "        plt.title('Training...')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Length of episodes batch')\n",
    "        plt.plot(torch.Tensor(all_epoch_lengths).numpy())\n",
    "        plt.pause(0.001)\n",
    "        display.clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last episode length is 391.82000732421875, epoch is 44\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Final plot\n",
    "plt.figure(2)\n",
    "plt.title('Training...')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Length of episodes batch')\n",
    "plt.plot(torch.Tensor(all_epoch_lengths).numpy())\n",
    "print(\"Last episode length is {}, epoch is {}\".format(epoch_episode_length, epoch))\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run it longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "686\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env._max_episode_steps = 5000\n",
    "\n",
    "state = env.reset() # reset environment\n",
    "for t in range(env._max_episode_steps): # rollout one episode until it finishes or stop after 200 steps\n",
    "    state_pytorch = torch.from_numpy(state).float().unsqueeze(0) # state=s\n",
    "    action = actorcritic_net.eval().select_action(state_pytorch).item()\n",
    "    state, reward, done, _ = env.step(action) # receive next state=s' and reward=r\n",
    "    env.render() # visualize state\n",
    "    if done:\n",
    "        print(t)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
