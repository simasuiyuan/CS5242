{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01 : Deep Q-Learning (DQN) - demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(torch.randint(10000,())) # random seed for pythorch random generator\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import gym\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from itertools import count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init state: [ 0.03073904  0.00145001 -0.03088818 -0.03131252]\n",
      "t= 0 action= 1 state= [ 0.03077  0.197   -0.03151 -0.33358] reward= 1.0 done= False\n",
      "t= 1 action= 1 state= [ 0.03471  0.39256 -0.03819 -0.63603] reward= 1.0 done= False\n",
      "t= 2 action= 1 state= [ 0.04256  0.58819 -0.05091 -0.94049] reward= 1.0 done= False\n",
      "t= 3 action= 0 state= [ 0.05432  0.39379 -0.06972 -0.66423] reward= 1.0 done= False\n",
      "t= 4 action= 0 state= [ 0.0622   0.1997  -0.083   -0.39429] reward= 1.0 done= False\n",
      "t= 5 action= 0 state= [ 0.06619  0.00585 -0.09089 -0.12888] reward= 1.0 done= False\n",
      "t= 6 action= 0 state= [ 0.06631 -0.18786 -0.09346  0.1338 ] reward= 1.0 done= False\n",
      "t= 7 action= 0 state= [ 0.06255 -0.38153 -0.09079  0.39559] reward= 1.0 done= False\n",
      "t= 8 action= 1 state= [ 0.05492 -0.18524 -0.08288  0.07572] reward= 1.0 done= False\n",
      "t= 9 action= 1 state= [ 0.05122  0.01096 -0.08136 -0.24191] reward= 1.0 done= False\n",
      "t= 10 action= 0 state= [ 0.05144 -0.18291 -0.0862   0.02404] reward= 1.0 done= False\n",
      "t= 11 action= 0 state= [ 0.04778 -0.37669 -0.08572  0.28833] reward= 1.0 done= False\n",
      "t= 12 action= 0 state= [ 0.04024 -0.57049 -0.07995  0.55279] reward= 1.0 done= False\n",
      "t= 13 action= 0 state= [ 0.02883 -0.76441 -0.0689   0.81925] reward= 1.0 done= False\n",
      "t= 14 action= 1 state= [ 0.01355 -0.56841 -0.05251  0.50572] reward= 1.0 done= False\n",
      "t= 15 action= 1 state= [ 0.00218 -0.37259 -0.0424   0.19696] reward= 1.0 done= False\n",
      "t= 16 action= 0 state= [-0.00527 -0.56708 -0.03846  0.47597] reward= 1.0 done= False\n",
      "t= 17 action= 1 state= [-0.01662 -0.37144 -0.02894  0.17142] reward= 1.0 done= False\n",
      "t= 18 action= 1 state= [-0.02404 -0.17592 -0.02551 -0.13025] reward= 1.0 done= False\n",
      "t= 19 action= 0 state= [-0.02756 -0.37066 -0.02812  0.15428] reward= 1.0 done= False\n",
      "t= 20 action= 0 state= [-0.03498 -0.56537 -0.02503  0.43796] reward= 1.0 done= False\n",
      "t= 21 action= 0 state= [-0.04628 -0.76013 -0.01627  0.72265] reward= 1.0 done= False\n",
      "t= 22 action= 1 state= [-0.06149 -0.56479 -0.00182  0.42489] reward= 1.0 done= False\n",
      "t= 23 action= 1 state= [-0.07278 -0.36964  0.00668  0.13163] reward= 1.0 done= False\n",
      "t= 24 action= 0 state= [-0.08017 -0.56486  0.00931  0.42642] reward= 1.0 done= False\n",
      "t= 25 action= 0 state= [-0.09147 -0.76011  0.01784  0.72202] reward= 1.0 done= False\n",
      "t= 26 action= 0 state= [-0.10667 -0.95547  0.03228  1.02027] reward= 1.0 done= False\n",
      "t= 27 action= 0 state= [-0.12578 -1.15101  0.05269  1.32291] reward= 1.0 done= False\n",
      "t= 28 action= 1 state= [-0.1488  -0.95659  0.07914  1.04717] reward= 1.0 done= False\n",
      "t= 29 action= 1 state= [-0.16794 -0.76261  0.10009  0.78034] reward= 1.0 done= False\n",
      "t= 30 action= 1 state= [-0.18319 -0.56899  0.1157   0.52075] reward= 1.0 done= False\n",
      "t= 31 action= 1 state= [-0.19457 -0.37567  0.12611  0.26665] reward= 1.0 done= False\n",
      "t= 32 action= 1 state= [-0.20208 -0.18255  0.13144  0.01625] reward= 1.0 done= False\n",
      "t= 33 action= 1 state= [-0.20573  0.01046  0.13177 -0.23224] reward= 1.0 done= False\n",
      "t= 34 action= 1 state= [-0.20552  0.20348  0.12712 -0.48063] reward= 1.0 done= False\n",
      "t= 35 action= 0 state= [-0.20145  0.00681  0.11751 -0.15074] reward= 1.0 done= False\n",
      "t= 36 action= 0 state= [-0.20132 -0.18978  0.1145   0.17658] reward= 1.0 done= False\n",
      "t= 37 action= 0 state= [-0.20511 -0.38634  0.11803  0.50308] reward= 1.0 done= False\n",
      "t= 38 action= 1 state= [-0.21284 -0.19306  0.12809  0.2498 ] reward= 1.0 done= False\n",
      "t= 39 action= 1 state= [-2.16700e-01  2.31393e-05  1.33085e-01  1.03215e-04] reward= 1.0 done= False\n",
      "t= 40 action= 0 state= [-0.2167  -0.19673  0.13309  0.33164] reward= 1.0 done= False\n",
      "t= 41 action= 1 state= [-0.22063 -0.00373  0.13972  0.08371] reward= 1.0 done= False\n",
      "t= 42 action= 0 state= [-0.22071 -0.20055  0.14139  0.417  ] reward= 1.0 done= False\n",
      "t= 43 action= 1 state= [-0.22472 -0.00768  0.14973  0.17203] reward= 1.0 done= False\n",
      "t= 44 action= 0 state= [-0.22487 -0.2046   0.15317  0.50795] reward= 1.0 done= False\n",
      "t= 45 action= 1 state= [-0.22897 -0.01193  0.16333  0.26718] reward= 1.0 done= False\n",
      "t= 46 action= 1 state= [-0.2292   0.18053  0.16868  0.03014] reward= 1.0 done= False\n",
      "t= 47 action= 1 state= [-0.22559  0.37288  0.16928 -0.20493] reward= 1.0 done= False\n",
      "t= 48 action= 0 state= [-0.21814  0.1758   0.16518  0.136  ] reward= 1.0 done= False\n",
      "t= 49 action= 1 state= [-0.21462  0.36821  0.1679  -0.10035] reward= 1.0 done= False\n",
      "t= 50 action= 1 state= [-0.20726  0.56058  0.16589 -0.33572] reward= 1.0 done= False\n",
      "t= 51 action= 0 state= [-0.19604  0.36354  0.15918  0.00435] reward= 1.0 done= False\n",
      "t= 52 action= 1 state= [-0.18877  0.55606  0.15927 -0.23419] reward= 1.0 done= False\n",
      "t= 53 action= 0 state= [-0.17765  0.35906  0.15458  0.10419] reward= 1.0 done= False\n",
      "t= 54 action= 1 state= [-0.17047  0.55167  0.15667 -0.13601] reward= 1.0 done= False\n",
      "t= 55 action= 0 state= [-0.15944  0.35469  0.15395  0.20172] reward= 1.0 done= False\n",
      "t= 56 action= 0 state= [-0.15234  0.15774  0.15798  0.53873] reward= 1.0 done= False\n",
      "t= 57 action= 0 state= [-0.14919 -0.03921  0.16876  0.87673] reward= 1.0 done= False\n",
      "t= 58 action= 0 state= [-0.14997 -0.23617  0.18629  1.21735] reward= 1.0 done= False\n",
      "t= 59 action= 1 state= [-0.1547  -0.04387  0.21064  0.98835] reward= 1.0 done= True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Env parameters\n",
    "env_seed = 1\n",
    "render = True # display on\n",
    "render = False # display off\n",
    "\n",
    "#Initialize the environment with the same seed/initialization value\n",
    "env = gym.make('CartPole-v0')\n",
    "env.seed(env_seed)\n",
    "\n",
    "#Reset the environment\n",
    "state = env.reset() \n",
    "print('init state:',state)\n",
    "\n",
    "#Rollout one episode until it finishes \n",
    "for t in count():  \n",
    "    action = torch.LongTensor(1).random_(0,2).item() # randomly generated action=a in {0,1}\n",
    "    state, reward, done, _ = env.step(action) # receive next state=s' and reward=r\n",
    "    print('t=',t, 'action=',action, 'state=',np.array_str(state, precision=5), 'reward=',reward, 'done=',done )\n",
    "    if render:\n",
    "        env.render() # see the state\n",
    "    if done:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay Memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple( 'Transition', ('state', 'action', 'next_state', 'reward', 'done') )\n",
    "\n",
    "# class of replay memory/experience \n",
    "class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def write(self, *args): # store transitions (s, a, s', r)\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def read(self, batch_size): # select a random batch of transitions \n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory size 1\n",
      "batch_transitions [Transition(state=tensor([ 0.0273, -0.0448, -0.0430,  0.0015]), action=tensor(0), next_state=tensor([ 0.0189, -0.0040,  0.0402,  0.0275]), reward=tensor(1.), done=tensor(0))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the replay memory\n",
    "memory = ReplayMemory(10000) \n",
    "\n",
    "#Write/store the transition in memory       \n",
    "state = torch.FloatTensor(env.reset())\n",
    "action = torch.tensor(0).long()\n",
    "next_state = torch.FloatTensor(env.reset())\n",
    "reward = torch.tensor(1).float()\n",
    "done = torch.tensor(0).long()\n",
    "memory.write(state,action,next_state,reward,done)\n",
    "print('memory size',memory.__len__())\n",
    "\n",
    "#Read a batch of transitions (s, a, s', r) from replay memory \n",
    "batch_size = 1\n",
    "batch_transitions = memory.read(batch_size)  \n",
    "print('batch_transitions',batch_transitions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the policy network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class of policy network\n",
    "class Q_NN(nn.Module): \n",
    "    \n",
    "    def __init__(self, net_parameters):\n",
    "        super(Q_NN, self).__init__()\n",
    "        input_dim = net_parameters['input_dim']\n",
    "        hidden_dim = net_parameters['hidden_dim']\n",
    "        output_dim = net_parameters['output_dim']\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim, bias=True)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim, bias=True)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        Q_scores = self.fc2(x) # scores over actions \n",
    "        return Q_scores\n",
    "    \n",
    "    def select_action(self, state, rand_act_pr): # select action w/ Q network\n",
    "        Q_scores = self.forward(state) # Q(a|s) scores of action a in state s\n",
    "        coin = random.random()\n",
    "        if coin < rand_act_pr: # (state,action) exploration process parametrized by rand_act_pr\n",
    "            action = torch.randint(0,2,()).item()\n",
    "        else:\n",
    "            action = Q_scores.argmax().item()\n",
    "        return action\n",
    "    \n",
    "    def loss(self, memory, baseline_Q_net, opt_parameters):\n",
    "        batch_size = opt_parameters['batch_size']\n",
    "        gamma = opt_parameters['gamma']\n",
    "        if memory.__len__()>=batch_size: # read a batch of transitions (s,a,s',r) in replay memory \n",
    "            batch_transitions = Transition(*zip(*memory.read(batch_size)))\n",
    "        else:\n",
    "            batch_transitions = Transition(*zip(*memory.read(memory.__len__()))) \n",
    "        batch_states = torch.stack([x for x in batch_transitions.state]).float() # state=s, size=B x 4\n",
    "        batch_next_states = torch.stack([x for x in batch_transitions.next_state]).float() # next_state=s', size=B x 4\n",
    "        batch_rewards = torch.stack([x for x in batch_transitions.reward]).float() # reward=r, size=B \n",
    "        batch_actions = torch.stack([x for x in batch_transitions.action]).long() # action=a, size=B\n",
    "        batch_dones = torch.stack([x for x in batch_transitions.done]).float() # done, size=B\n",
    "        Q = self.forward(batch_states).gather(dim=1,index=batch_actions.unsqueeze(1)) # Q_W(a|s), size=B x 1\n",
    "        max_baseline_Q_net = baseline_Q_net.forward(batch_next_states).max(dim=1)[0].detach() * batch_dones \n",
    "        Q_target = batch_rewards.unsqueeze(1) + \\\n",
    "            gamma * max_baseline_Q_net.unsqueeze(1) # Q_target = r + gamma . max_a' Q_W^BL(a'|s'), size=B x 1 \n",
    "        loss = nn.MSELoss()(Q,Q_target) # MSE_Loss(error = Q_target - Q_W)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "# class of rollout episodes\n",
    "class Rollout_Episodes():\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Rollout_Episodes, self).__init__()\n",
    "        \n",
    "    def rollout_batch_episodes(self, env, memory, opt_parameters, Q_Net, write_memory=True):\n",
    "        nb_episodes_per_batch = opt_parameters['nb_episodes_per_batch']\n",
    "        env_seeds = opt_parameters['env_seed']\n",
    "        rand_act_pr = opt_parameters['rand_act_pr']\n",
    "        batch_episode_lengths = [] \n",
    "        for episode in range(nb_episodes_per_batch):\n",
    "            env.seed(env_seeds[episode].item()) # start with random seed\n",
    "            state = env.reset() # initial state\n",
    "            for t in range(1000): # rollout one episode until it finishes\n",
    "                state_pytorch = torch.from_numpy(state).float().unsqueeze(0) # state=s\n",
    "                action = Q_Net.select_action(state_pytorch, rand_act_pr) # select action=a from state=s\n",
    "                next_state, reward, done, _ = env.step(action) # receive next_state=s' and reward=r\n",
    "                done_mask = 0.0 if done else 1.0\n",
    "                if write_memory:\n",
    "                    memory.write(torch.tensor(state),torch.tensor(action),torch.tensor(next_state),\n",
    "                                 torch.tensor(reward),torch.tensor(done_mask)) \n",
    "                state = next_state\n",
    "                if done:\n",
    "                    batch_episode_lengths.append(t)\n",
    "                    break\n",
    "        return batch_episode_lengths\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_NN(\n",
      "  (fc1): Linear(in_features=4, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "Q_NN(\n",
      "  (fc1): Linear(in_features=4, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "memory size 0\n",
      "batch_episode_lengths: [8, 7, 9]\n",
      "memory size 27\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# network parameters\n",
    "net_parameters = {}\n",
    "net_parameters['input_dim'] = 4\n",
    "net_parameters['hidden_dim'] = 128\n",
    "net_parameters['output_dim'] = 2\n",
    "\n",
    "# instantiate networks\n",
    "Qnet = Q_NN(net_parameters)\n",
    "print(Qnet)\n",
    "baseline_Qnet = Q_NN(net_parameters).eval() \n",
    "baseline_Qnet.load_state_dict(Qnet.state_dict()) \n",
    "print(baseline_Qnet)\n",
    "\n",
    "# instantiate rollout\n",
    "rollout_Qnet = Rollout_Episodes()\n",
    "memory = ReplayMemory(10000) \n",
    "print('memory size',memory.__len__())\n",
    "\n",
    "# optimization parameters\n",
    "opt_parameters = {}\n",
    "opt_parameters['nb_episodes_per_batch'] = 3\n",
    "opt_parameters['env_seed'] = torch.LongTensor(opt_parameters['nb_episodes_per_batch']).random_(1,10000)\n",
    "opt_parameters['rand_act_pr'] = 0.01\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "batch_episode_lengths = rollout_Qnet.rollout_batch_episodes(env, memory, opt_parameters, Qnet)\n",
    "print('batch_episode_lengths:',batch_episode_lengths)\n",
    "print('memory size',memory.__len__())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_episode_lengths: [8, 7, 8]\n",
      "memory size 26\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# instantiate memory\n",
    "memory = ReplayMemory(10000) \n",
    "\n",
    "# optimization parameters\n",
    "opt_parameters = {}\n",
    "opt_parameters['lr'] = 0.001 \n",
    "opt_parameters['nb_episodes_per_batch'] = 3\n",
    "opt_parameters['nb_batches_per_epoch'] = 10\n",
    "opt_parameters['env_seed'] = torch.LongTensor(opt_parameters['nb_episodes_per_batch']).random_(1,10000)\n",
    "opt_parameters['batch_size'] = 10\n",
    "opt_parameters['gamma'] = 0.999\n",
    "opt_parameters['rand_act_pr'] = 0.01\n",
    "\n",
    "batch_episode_lengths = Rollout_Episodes().rollout_batch_episodes(env, memory, opt_parameters, Qnet)\n",
    "print('batch_episode_lengths:',batch_episode_lengths)\n",
    "print('memory size',memory.__len__())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9607, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loss\n",
    "loss = Qnet.loss(memory, baseline_Qnet, opt_parameters)\n",
    "print('loss:',loss)\n",
    "\n",
    "# Backward pass\n",
    "lr = opt_parameters['lr']\n",
    "optimizer = torch.optim.Adam(Qnet.parameters(), lr=lr)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch(env, memory, Q_net, baseline_Q_net, opt_parameters, optimizer):\n",
    "    Q_net.train()\n",
    "    baseline_Q_net.eval()\n",
    "    rollout_Q_net = Rollout_Episodes()\n",
    "    epoch_loss = 0\n",
    "    nb_data = 0\n",
    "    epoch_episode_length = 0\n",
    "    epoch_episode_lengths = []\n",
    "    nb_batches_per_epoch = opt_parameters['nb_batches_per_epoch']\n",
    "    for iter in range(nb_batches_per_epoch):\n",
    "        opt_parameters['env_seed'] = torch.LongTensor(opt_parameters['nb_episodes_per_batch']).random_(1,10000)\n",
    "        batch_episode_lengths = rollout_Q_net.rollout_batch_episodes(env, memory, opt_parameters, Q_net)\n",
    "        loss = Q_net.loss(memory, baseline_Q_net, opt_parameters)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.detach().item() \n",
    "        nb_data += len(batch_episode_lengths)\n",
    "        epoch_episode_length += torch.tensor(batch_episode_lengths).float().sum()\n",
    "        epoch_episode_lengths.append(epoch_episode_length) \n",
    "    epoch_loss /= nb_data\n",
    "    epoch_episode_length /= nb_data\n",
    "    return epoch_loss, epoch_episode_length, epoch_episode_lengths\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO UPDATE BASELINE - epoch: 150\n",
      "Training done.\n",
      "Last episode length is 393.0, epoch is 150, random_action_prob is 0.01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# network parameters\n",
    "net_parameters = {}\n",
    "net_parameters['input_dim'] = 4\n",
    "net_parameters['hidden_dim'] = 256\n",
    "net_parameters['output_dim'] = 2\n",
    "\n",
    "# instantiate network\n",
    "Q_net = Q_NN(net_parameters)\n",
    "baseline_Q_net = Q_NN(net_parameters).eval() \n",
    "baseline_Q_net.load_state_dict(Q_net.state_dict()) \n",
    "print(Q_net)\n",
    "print(baseline_Q_net)\n",
    "\n",
    "# instantiate memory\n",
    "memory = ReplayMemory(50000) \n",
    "\n",
    "# optimization parameters\n",
    "opt_parameters = {}\n",
    "opt_parameters['lr'] = 0.0005 \n",
    "opt_parameters['nb_episodes_per_batch'] = 1 \n",
    "opt_parameters['nb_batches_per_epoch'] = 50 \n",
    "opt_parameters['env_seed'] = torch.LongTensor(opt_parameters['nb_episodes_per_batch']).random_(1,10000)\n",
    "opt_parameters['batch_size'] = 128 \n",
    "opt_parameters['gamma'] = 0.999\n",
    "opt_parameters['baseline_update'] = 1\n",
    "init_rand_act_pr = 0.2 # starting random action prob\n",
    "opt_parameters['rand_act_pr'] = init_rand_act_pr \n",
    "opt_parameters_baseline = opt_parameters.copy()\n",
    "opt_parameters_baseline['nb_episodes_per_batch'] = 5\n",
    "opt_parameters_baseline['rand_act_pr'] = 0.0\n",
    "\n",
    "optimizer = torch.optim.Adam(Q_net.parameters(), lr=opt_parameters['lr'])\n",
    "\n",
    "# select maximum episode length to learn\n",
    "env = gym.make('CartPole-v0')\n",
    "env._max_episode_steps = 400 # 200 400\n",
    "env.spec.reward_threshold = 0.975* env._max_episode_steps\n",
    "print('env._max_episode_steps',env._max_episode_steps)\n",
    "\n",
    "# train loop\n",
    "running_length = 10\n",
    "all_epoch_lengths = []\n",
    "batch_episode_lengths_update = 0\n",
    "start = time.time()\n",
    "for epoch in range(200):\n",
    "    \n",
    "    # train one epoch\n",
    "    epoch_train_loss, epoch_episode_length, epoch_episode_lengths = \\\n",
    "        train_one_epoch(env, memory, Q_net, baseline_Q_net, opt_parameters, optimizer)\n",
    "    \n",
    "    # update random_action_prob(=lr), linear annealing from xx% to 1%  \n",
    "    opt_parameters['rand_act_pr'] = max(0.01, init_rand_act_pr - init_rand_act_pr*(epoch/float(100)))  \n",
    "        \n",
    "    # update baseline if current policy better (use greedy mode for evaluation)\n",
    "    if not epoch%opt_parameters['baseline_update']:\n",
    "        opt_parameters_baseline['env_seed'] = torch.LongTensor(opt_parameters_baseline['nb_episodes_per_batch']).random_(1,10000)\n",
    "        opt_parameters_baseline['rand_act_pr'] = opt_parameters['rand_act_pr']\n",
    "        batch_episode_lengths_update = Rollout_Episodes().rollout_batch_episodes(env, memory, opt_parameters, Q_net, False)\n",
    "        batch_episode_lengths_update_baseline = Rollout_Episodes().rollout_batch_episodes(env, memory, opt_parameters, Q_net, False)\n",
    "        if torch.Tensor(batch_episode_lengths_update).mean() > torch.Tensor(batch_episode_lengths_update_baseline).mean():\n",
    "            print('UPDATE BASELINE - epoch:',epoch)\n",
    "            baseline_Q_net.load_state_dict(Q_net.state_dict())\n",
    "        else:\n",
    "            print('NO UPDATE BASELINE - epoch:',epoch)\n",
    "              \n",
    "    # stop training when reward is high\n",
    "    if epoch_episode_length > env.spec.reward_threshold:\n",
    "        print('Training done.')\n",
    "        print(\"Last episode length is {}, epoch is {}, random_action_prob is {}\".\n",
    "              format(epoch_episode_length, epoch, opt_parameters['rand_act_pr']))\n",
    "        break\n",
    "        \n",
    "    # print intermediate info\n",
    "    if not epoch%1:\n",
    "        print('Epoch: {}, rand_act_pr: {:.4f}, time: {:.4f}, train_loss: {:.4f}, episode_length: {:.4f}'.format(epoch, opt_parameters['rand_act_pr'], time.time()-start, epoch_train_loss, epoch_episode_length))\n",
    "        print('           memory size: {}, Qnet eval: {:.4f}, Qnet baseline eval: {:.4f}'.format(memory.__len__(), torch.Tensor(batch_episode_lengths_update).mean().item(), torch.Tensor(batch_episode_lengths_update_baseline).mean().item() ))\n",
    "      \n",
    "    # plot all epochs\n",
    "    all_epoch_lengths.append(epoch_episode_length)\n",
    "    if not epoch%1:\n",
    "        plt.figure(2)\n",
    "        plt.title('Training...')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Length of episodes batch')\n",
    "        plt.plot(torch.Tensor(all_epoch_lengths).numpy())\n",
    "        plt.pause(0.001)\n",
    "        display.clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last episode length is 393.0, epoch is 150 and rand_act_pr 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Final plot\n",
    "plt.figure(2)\n",
    "plt.title('Training...')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Length of episodes batch')\n",
    "plt.plot(torch.Tensor(all_epoch_lengths).numpy())\n",
    "print(\"Last episode length is {}, epoch is {} and rand_act_pr {}\".format(epoch_episode_length, epoch, opt_parameters['rand_act_pr']))\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run it longer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env._max_episode_steps = 5000\n",
    "\n",
    "state = env.reset() # reset environment\n",
    "for t in range(env._max_episode_steps): # rollout one episode until it finishes or stop after 200 steps\n",
    "    state_pytorch = torch.from_numpy(state).float().unsqueeze(0) # state=s\n",
    "    action = Q_net.eval().select_action(state_pytorch, 0.0) # select action=a from state=s\n",
    "    state, reward, done, _ = env.step(action) # receive next state=s' and reward=r\n",
    "    env.render() # visualize state\n",
    "    if done:\n",
    "        print(t)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
