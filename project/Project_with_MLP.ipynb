{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b6af0f",
   "metadata": {},
   "source": [
    "# Project Motivation\n",
    "With the rise of telederm, users upload a photo of their face to aid dermatologists in the assessment. They then count and determine the type of every acne. However, this process is labour intensive, prone to bias and does not scale well. Hence, being able to identify the type of acne found on the face using computer vision, this creates room for automated acne diagnosis. Alternatively, in recommendation systems for skincare products on ecommerce sites, this data can empower the algorithms behind by acting as an additional source of information to recommend specific products which would be ideal to remedy the acne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46daf24d",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "Using our learning model, users can take a photo of themselves and upload it. We will then segment the photo into windows and let the model classify the type of acne. With the output classification, we will then determine the count of every acne type on usersâ€™ faces. This will then provide the dermatologist with data to determine the best course of action for the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb92538",
   "metadata": {},
   "source": [
    "# Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b97607",
   "metadata": {},
   "source": [
    "## 1. Data Scraping\n",
    "For our dataset, we will be scraping acne images from https://dermnetnz.org/. This section loops through `img` tag of the gallery using BeautifulSoup library and downloads them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94135ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "def download_image(image_url, image_name):\n",
    "    url = image_url\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(image_name, 'wb') as out_file:\n",
    "        shutil.copyfileobj(response.raw, out_file)\n",
    "    del response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a332492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_dermnet(url):\n",
    "    html_page = requests.get(url)\n",
    "    soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "    textBlock = soup.find('section', class_=\"textBlock\")\n",
    "    imgs = textBlock.findAll('img')\n",
    "    img_dataset = pd.DataFrame([[img.attrs['alt'], \"https://dermnetnz.org/\" + img.attrs['data-src']] for img in imgs], columns=['alt', 'image_url'])\n",
    "    img_dataset['image_name'] = [f'data/image_{e}.jpg' for e in range(img_dataset.shape[0])]\n",
    "    return img_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7a92779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download images\n",
    "img_dataset = scrape_dermnet(\"https://dermnetnz.org/topics/acne-face-images\")\n",
    "for row in img_dataset.itertuples():\n",
    "    download_image(row.image_url, row.image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1715f7a3",
   "metadata": {},
   "source": [
    "253 images were successfully scraped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbebf79",
   "metadata": {},
   "source": [
    "## 1.1 Sliding Window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1a9552",
   "metadata": {},
   "source": [
    "As each facial image may contain multiple acne of different acne types, it will be best to break it into smaller patches to aid with the counting. We will construct a sliding window of size 50 x 50 and stride 50, iterating across each image to generate patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1162eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, rename\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cdc646a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [join('scraped_data', f) for f in listdir('scraped_data') if isfile(join('scraped_data', f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04ecb4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set size of sliding window\n",
    "window_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cb605ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing images\n",
    "counter = 0\n",
    "for image_path in images:\n",
    "    img = np.asarray(Image.open(image_path))\n",
    "    for i in range(0,img.shape[0],window_size):\n",
    "        for j in range(0,img.shape[1],window_size):\n",
    "            sub_img = img[i:i+window_size, j:j+window_size, :]\n",
    "            # Save image\n",
    "            img_name = image_path.split('/')[-1].split('.')[0]\n",
    "            Image.fromarray(sub_img).save(f'temp_dataset/{counter}.jpg')\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fb561b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv for tagging\n",
    "cropped_images = sorted([f for f in listdir('temp_dataset') if isfile(join('temp_dataset', f))])\n",
    "shuffled_images_name = cropped_images.copy()\n",
    "random.shuffle(shuffled_images_name)\n",
    "filenames_rows = list(zip(cropped_images, shuffled_images_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6cc82e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_df = pd.DataFrame(filenames_rows, columns=['Image File', 'New Image Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "536e64b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename files with shuffled names\n",
    "for idx, row in tagging_df.iterrows():\n",
    "    rename(f'temp_dataset/{row[\"Image File\"]}', f'dataset/{row[\"New Image Name\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "26a935e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image File</th>\n",
       "      <th>New Image Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>2193.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>4976.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>2599.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.jpg</td>\n",
       "      <td>6201.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>1952.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image File New Image Name\n",
       "0      0.jpg       2193.jpg\n",
       "1      1.jpg       4976.jpg\n",
       "2     10.jpg       2599.jpg\n",
       "3    100.jpg       6201.jpg\n",
       "4   1000.jpg       1952.jpg"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53be53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_df.to_csv('original_filename.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c41856f",
   "metadata": {},
   "source": [
    "Through this process, we generated approximately 7,500 patches. We then manually labelled 1,500 patches as our dataset to split into train and test later on. These patches were labelled as one of these 6 classes:\n",
    "- Not face - 0\n",
    "- Normal skin - 1\n",
    "- Pustule - 2\n",
    "- Whitehead - 3\n",
    "- Blackhead - 4\n",
    "- Cyst - 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d799171b",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1173e4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, rename\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "from skimage.util import random_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caafacd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba65ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd63930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.jpg      1\n",
       "1    1.jpg      1\n",
       "2    2.jpg      5\n",
       "3    3.jpg      1\n",
       "4    4.jpg      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2575669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1664, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fde6234",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ca8f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(labels):\n",
    "    X = []\n",
    "    y = []\n",
    "    for row in labels.itertuples():\n",
    "        img_path = join('dataset', row.filename)\n",
    "        img = np.asarray(Image.open(img_path))\n",
    "        \n",
    "        # Keep squares for now\n",
    "        if img.shape[0] == img.shape[1]:\n",
    "            y.append(row.label)\n",
    "            X.append(img)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8896db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(X_train, y_train):\n",
    "    final_X_train = []\n",
    "    final_y_train = []\n",
    "    for i in range(len(X_train)):\n",
    "        final_X_train.append(X_train[i])\n",
    "        final_X_train.append(rotate(X_train[i], angle=45, mode = 'wrap'))\n",
    "        final_X_train.append(np.fliplr(X_train[i]))\n",
    "        final_X_train.append(np.flipud(X_train[i]))\n",
    "        final_X_train.append(random_noise(X_train[i],var=0.2**2))\n",
    "        \n",
    "        final_y_train += [y_train[i]] * 5\n",
    "    return final_X_train, final_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31eb5a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(scores, labels):\n",
    "    num_data = scores.size(0)\n",
    "    predicted_labels = scores.argmax(dim=1)\n",
    "    indicator = (predicted_labels == labels)\n",
    "    num_matches = indicator.sum()\n",
    "    return 100*num_matches.float()/num_data  \n",
    "\n",
    "def get_error( scores , labels ):\n",
    "\n",
    "    bs=scores.size(0)\n",
    "    predicted_labels = scores.argmax(dim=1)\n",
    "    indicator = (predicted_labels == labels)\n",
    "    num_matches=indicator.sum()\n",
    "    \n",
    "    return 1-num_matches.float()/bs   \n",
    "\n",
    "def eval_on_test_set(test_data, test_label, net, mean, std, bs):\n",
    "\n",
    "    running_error=0\n",
    "    running_acc = 0\n",
    "    num_batches=0\n",
    "\n",
    "    for i in range(0,500,bs):\n",
    "\n",
    "        minibatch_data =  test_data[i:i+bs]\n",
    "        minibatch_label = test_label[i:i+bs]\n",
    "        \n",
    "        inputs = (minibatch_data - mean)/std\n",
    "\n",
    "        scores= net( inputs ) \n",
    "\n",
    "        error = get_error( scores.detach() , minibatch_label)\n",
    "        acc = get_accuracy( scores.detach() , minibatch_label)\n",
    "\n",
    "        running_error += error.item()\n",
    "        running_acc += acc.item()\n",
    "\n",
    "        num_batches+=1\n",
    "\n",
    "    total_error = running_error/num_batches\n",
    "    total_acc = running_acc/num_batches\n",
    "    print(running_error, num_batches)\n",
    "    print( 'error rate on test set =', total_error*100 ,'percent')\n",
    "    print('accuracy =', total_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "643b5087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(X_train, y_train):\n",
    "    final_X_train = []\n",
    "    final_y_train = []\n",
    "    label_distribution = Counter(y_train)\n",
    "    plt.bar(label_distribution.keys(), label_distribution.values())\n",
    "    plt.show()\n",
    "    print(label_distribution)\n",
    "    max_count_label = max(label_distribution, key=label_distribution.get)\n",
    "    min_count_label = min(label_distribution, key=label_distribution.get)\n",
    "    for i in range(len(X_train)):\n",
    "        label_key = y_train[i]\n",
    "        if label_distribution[max_count_label] - label_distribution[label_key] >= 10 or label_distribution[max_count_label] - label_distribution[min_count_label] <= 6:\n",
    "            final_X_train.append(X_train[i])\n",
    "            angle = 90\n",
    "            while angle < 360:\n",
    "                final_X_train.append(rotate(X_train[i], angle=angle, mode = 'wrap'))\n",
    "                angle+=90\n",
    "            \n",
    "            final_X_train.append(random_noise(X_train[i],var=0.05**2))\n",
    "        \n",
    "            final_y_train += [y_train[i]] * 5\n",
    "            label_distribution = Counter(final_y_train)\n",
    "            max_count = max(label_distribution, key=label_distribution.get)\n",
    "            min_count = min(label_distribution, key=label_distribution.get)\n",
    "    print(label_distribution)\n",
    "    plt.bar(label_distribution.keys(), label_distribution.values())\n",
    "    plt.show()\n",
    "    return final_X_train, final_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2246b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_images(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "820366f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 156, 1: 309, 2: 224, 3: 169, 4: 157, 0: 135})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd6ca14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 13, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a528303a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 1235, 2: 895, 3: 675, 4: 630, 5: 625, 0: 540})\n",
      "Counter({2: 2855, 4: 2730, 3: 2705, 0: 2700, 5: 2680, 1: 2660})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, y_train = augment_data(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb48322e",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "482a6015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d950c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class convnet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_channel, hidden_layer, num_class):\n",
    "\n",
    "        super(convnet, self).__init__()\n",
    "      \n",
    "        self.conv1a = torch.nn.Conv2d(input_channel, hidden_layer,  kernel_size=5, padding=1 )\n",
    "        self.pool1a  = torch.nn.MaxPool2d(2,2)\n",
    "        self.conv1b = torch.nn.Conv2d(hidden_layer,  hidden_layer,  kernel_size=5, padding=1 )\n",
    "        self.pool1b  = torch.nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(12100, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1a(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.pool1a(x)\n",
    "        x = self.conv1b(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.pool1b(x)\n",
    "        \n",
    "        x = x.view(-1, 12100)\n",
    "        x = self.linear1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8886a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(X_train, y_train, X_test, y_test):\n",
    "    X_train = torch.from_numpy(np.array(X_train).astype(np.float32))\n",
    "    y_train = torch.from_numpy(np.array(y_train).astype(np.float32)).type(torch.LongTensor)\n",
    "    X_test = torch.from_numpy(np.array(X_test).astype(np.float32))\n",
    "    y_test = torch.from_numpy(np.array(y_test).astype(np.float32)).type(torch.LongTensor)\n",
    "    X_train = X_train.view(-1, 3, 50, 50)\n",
    "    X_test = X_test.view(-1, 3, 50, 50)\n",
    "    \n",
    "    my_lr = 0.001\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    bs = 128\n",
    "    num_class = 6\n",
    "\n",
    "    net = convnet(3, 100, num_class)\n",
    "    mean = X_train.mean()\n",
    "    std = X_train.std()\n",
    "    num_train_data = X_train.size()[0]\n",
    "    \n",
    "    for epoch in range(2):\n",
    "        # create a new optimizer at the beginning of each epoch: give the current learning rate.   \n",
    "        optimizer=torch.optim.Adam( net.parameters() , lr=my_lr )\n",
    "\n",
    "        # set the running quatities to zero at the beginning of the epoch\n",
    "        running_loss=0\n",
    "        running_error=0\n",
    "        running_acc = 0\n",
    "        num_batches=0\n",
    "\n",
    "        # set the order in which to visit the image from the training set\n",
    "        shuffled_indices = torch.randperm(num_train_data)\n",
    "\n",
    "        for count in range(0,num_train_data,bs):\n",
    "\n",
    "            # Set the gradients to zeros\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # create a minibatch       \n",
    "            indices = shuffled_indices[count:count+bs]\n",
    "            minibatch_data =  X_train[indices]\n",
    "            minibatch_label =  y_train[indices]\n",
    "\n",
    "\n",
    "            # normalize the minibatch (this is the only difference compared to before!)\n",
    "            inputs = (minibatch_data - mean)/std\n",
    "\n",
    "            # tell Pytorch to start tracking all operations that will be done on \"inputs\"\n",
    "            inputs.requires_grad_()\n",
    "\n",
    "            # forward the minibatch through the net \n",
    "            scores=net( inputs ) \n",
    "\n",
    "            # Compute the average of the losses of the data points in the minibatch\n",
    "            loss =  criterion( scores , minibatch_label) \n",
    "\n",
    "            # backward pass to compute dL/dU, dL/dV and dL/dW   \n",
    "            loss.backward()\n",
    "\n",
    "            # do one step of stochastic gradient descent: U=U-lr(dL/dU), V=V-lr(dL/dU), ...\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            # START COMPUTING STATS\n",
    "\n",
    "            # add the loss of this batch to the running loss\n",
    "            running_loss += loss.detach().item()\n",
    "\n",
    "            # compute the error made on this batch and add it to the running error       \n",
    "            error = get_error( scores.detach() , minibatch_label)\n",
    "            acc = get_accuracy(scores.detach() , minibatch_label)\n",
    "            running_error += error.item()\n",
    "            running_acc += acc.item()\n",
    "\n",
    "            num_batches+=1        \n",
    "\n",
    "\n",
    "        # compute stats for the full training set\n",
    "        total_loss = running_loss/num_batches\n",
    "        total_error = running_error/num_batches\n",
    "        total_acc = running_acc/num_batches\n",
    "\n",
    "\n",
    "        print('epoch=',epoch, '\\t loss=', total_loss , '\\t error=', total_error*100 ,'percent')\n",
    "        print('accuracy =', total_acc)\n",
    "        print(' ')\n",
    "\n",
    "    eval_on_test_set(X_test, y_test, net, mean, std, bs)\n",
    "    return net, mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "97e6a90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0 \t loss= 1.807276802137494 \t error= 82.66964475624263 percent\n",
      "accuracy = 17.330355256795883\n",
      " \n",
      "epoch= 1 \t loss= 1.7822381611913443 \t error= 82.54097602330148 percent\n",
      "accuracy = 17.459023967385292\n",
      " \n",
      "nan 4\n",
      "error rate on test set = nan percent\n",
      "accuracy = nan\n"
     ]
    }
   ],
   "source": [
    "model, mean, std = train_network(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f40306e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "733325ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_X = pd.read_csv('df_X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7d97ffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_df_X.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8d57caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = np.asarray(pd.read_csv('df_y_test.csv')).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "652fed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = torch.from_numpy(np.array(test_X).astype(np.float32)).view(-1, 3, 50, 50)\n",
    "test_input = (test_input - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ce143bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=model(test_input) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "be214a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc_and_conf_mat(scores, actual_labels):\n",
    "    y_pred = scores.detach().numpy()\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    indicator = (y_pred == actual_labels)\n",
    "    num_matches = indicator.sum()\n",
    "    acc = 100*num_matches/len(y_pred)\n",
    "    conf_mat = confusion_matrix(actual_labels, y_pred)\n",
    "    return acc, conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "086eff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, conf_mat = compute_acc_and_conf_mat(scores, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2d6a4d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1   2  3  4  5\n",
       "0  16  0  43  0  0  0\n",
       "1  15  0  70  0  0  0\n",
       "2  21  0  52  0  0  0\n",
       "3   8  0  61  0  0  0\n",
       "4   8  0  51  0  0  0\n",
       "5   6  0  39  0  0  0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(conf_mat, columns=range(0,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d8dcd9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.435897435897434"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa4ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
