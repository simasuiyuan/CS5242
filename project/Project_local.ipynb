{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from keras.preprocessing.image import load_img \n",
    "from keras.preprocessing.image import img_to_array \n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "# models \n",
    "from keras.applications.vgg16 import VGG16 \n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "\n",
    "# clustering and dimension reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from src.dataLoader import dataLoader\n",
    "from src.utils import image_utils, ismember\n",
    "\n",
    "from src.preprocessing import imadjust,imagecrop,imagePaddingByShape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataLoader(\"../dataset\")\n",
    "\n",
    "# fileNameList = [str(imgIdx)+\".jpg\" for imgIdx in range(0,1501)]\n",
    "# imageFileList = dataset.LoadFileList(fileNameList=fileNameList)\n",
    "# imageFileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, rename\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "from skimage.util import random_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.jpg      1\n",
       "1    1.jpg      1\n",
       "2    2.jpg      5\n",
       "3    3.jpg      4\n",
       "4    4.jpg      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1501, 2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('labels.csv')\n",
    "display(labels.head())\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(labels):\n",
    "    X = []\n",
    "    y = []\n",
    "    for row in labels.itertuples():\n",
    "        img_path = join('../dataset', row.filename)\n",
    "        # print(row.filename)\n",
    "        # print(img_path)\n",
    "        # img = np.asarray(Image.open(img_path))\n",
    "        img = load_img(img_path, target_size=(224,224))\n",
    "        img = np.array(img) \n",
    "        # Keep squares for now\n",
    "        if img.shape[0] == img.shape[1]:\n",
    "            y.append(row.label)\n",
    "            X.append(img)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(X_train, y_train):\n",
    "    final_X_train = []\n",
    "    final_y_train = []\n",
    "    for i in range(len(X_train)):\n",
    "        final_X_train.append(X_train[i])\n",
    "        final_X_train.append(rotate(X_train[i], angle=45, mode = 'wrap'))\n",
    "        final_X_train.append(np.fliplr(X_train[i]))\n",
    "        final_X_train.append(np.flipud(X_train[i]))\n",
    "        final_X_train.append(random_noise(X_train[i],var=0.2**2))\n",
    "        \n",
    "        final_y_train += [y_train[i]] * 5\n",
    "    return final_X_train, final_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(scores, labels):\n",
    "    num_data = scores.size(0)\n",
    "    predicted_labels = scores.argmax(dim=1)\n",
    "    indicator = (predicted_labels == labels)\n",
    "    num_matches = indicator.sum()\n",
    "    return 100*num_matches.float()/num_data  \n",
    "\n",
    "def get_error( scores , labels ):\n",
    "\n",
    "    bs=scores.size(0)\n",
    "    predicted_labels = scores.argmax(dim=1)\n",
    "    indicator = (predicted_labels == labels)\n",
    "    num_matches=indicator.sum()\n",
    "    \n",
    "    return 1-num_matches.float()/bs   \n",
    "\n",
    "def eval_on_test_set(test_data, test_label, net, mean, std, bs):\n",
    "\n",
    "    running_error=0\n",
    "    running_acc = 0\n",
    "    num_batches=0\n",
    "\n",
    "    for i in range(0,500,bs):\n",
    "\n",
    "        minibatch_data =  test_data[i:i+bs]\n",
    "        minibatch_label = test_label[i:i+bs]\n",
    "        \n",
    "        inputs = (minibatch_data - mean)/std\n",
    "\n",
    "        scores= net( inputs ) \n",
    "\n",
    "        error = get_error( scores.detach() , minibatch_label)\n",
    "        acc = get_accuracy( scores.detach() , minibatch_label)\n",
    "\n",
    "        running_error += error.item()\n",
    "        running_acc += acc.item()\n",
    "\n",
    "        num_batches+=1\n",
    "\n",
    "    total_error = running_error/num_batches\n",
    "    total_acc = running_acc/num_batches\n",
    "    print(running_error, num_batches)\n",
    "    print( 'error rate on test set =', total_error*100 ,'percent')\n",
    "    print('accuracy =', total_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1501, 224, 224, 3)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_images(labels)\n",
    "np.array(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 444, 5: 185, 4: 107, 2: 253, 3: 119, 0: 393})"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.15 MiB for an array with shape (224, 224, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24464/4259464300.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maugment_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24464/3667365829.py\u001b[0m in \u001b[0;36maugment_data\u001b[1;34m(X_train, y_train)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mfinal_X_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfliplr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mfinal_X_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflipud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mfinal_X_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_noise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mfinal_y_train\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\deeplearn_course\\lib\\site-packages\\skimage\\util\\noise.py\u001b[0m in \u001b[0;36mrandom_noise\u001b[1;34m(image, mode, seed, clip, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;34m'amount'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;34m'salt_vs_pepper'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         'local_vars': np.zeros_like(image) + 0.01}\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     allowedkwargs = {\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mzeros_like\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\deeplearn_course\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mzeros_like\u001b[1;34m(a, dtype, order, subok, shape)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \"\"\"\n\u001b[1;32m--> 138\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;31m# needed instead of a 0 to get same result as zeros for for string dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mempty_like\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.15 MiB for an array with shape (224, 224, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "X_train, y_train = augment_data(X_train, y_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# class convnet(torch.nn.Module):\n",
    "\n",
    "#     def __init__(self, input_channel, hidden_layer, num_class):\n",
    "\n",
    "#         super(convnet, self).__init__()\n",
    "      \n",
    "#         self.conv1a = torch.nn.Conv2d(input_channel, hidden_layer,  kernel_size=5, padding=1 )\n",
    "#         self.pool1a  = torch.nn.MaxPool2d(2,2)\n",
    "#         self.conv1b = torch.nn.Conv2d(hidden_layer,  hidden_layer,  kernel_size=5, padding=1 )\n",
    "#         self.pool1b  = torch.nn.MaxPool2d(2,2)\n",
    "        \n",
    "#         self.linear1 = torch.nn.Linear(12100, num_class)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1a(x)\n",
    "#         x = torch.nn.functional.relu(x)\n",
    "#         x = self.pool1a(x)\n",
    "#         x = self.conv1b(x)\n",
    "#         x = torch.nn.functional.relu(x)\n",
    "#         x = self.pool1b(x)\n",
    "        \n",
    "#         x = x.view(-1, 12100)\n",
    "#         x = self.linear1(x)\n",
    "        \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import utils\n",
    "import time\n",
    "\n",
    "class VGG_convnet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_channel, num_class):\n",
    "\n",
    "        super(VGG_convnet, self).__init__()\n",
    "        \n",
    "        # block 1:         3 x 50 x 50 --> 64 x 25 x 25        \n",
    "        self.conv1a = nn.Conv2d(input_channel,   64,  kernel_size=3, padding=1 )\n",
    "        self.conv1b = nn.Conv2d(64,  64,  kernel_size=3, padding=1 )\n",
    "        self.pool1  = nn.MaxPool2d(2,2)\n",
    "\n",
    "        # block 2:         64 x 25 x 25 --> 128 x 8 x 8\n",
    "        self.conv2a = nn.Conv2d(64,  128, kernel_size=3, padding=1 )\n",
    "        self.conv2b = nn.Conv2d(128, 128, kernel_size=3, padding=1 )\n",
    "        self.pool2  = nn.MaxPool2d(2,2)\n",
    "\n",
    "        # block 3:         128 x 8 x 8 --> 256 x 4 x 4        \n",
    "        self.conv3a = nn.Conv2d(128, 256, kernel_size=3, padding=1 )\n",
    "        self.conv3b = nn.Conv2d(256, 256, kernel_size=3, padding=1 )\n",
    "        self.pool3  = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        #block 4:          256 x 4 x 4 --> 512 x 2 x 2\n",
    "        self.conv4a = nn.Conv2d(256, 512, kernel_size=3, padding=1 )\n",
    "        self.pool4  = nn.MaxPool2d(2,2)\n",
    "\n",
    "        # linear layers:   512 x 2 x 2 --> 4608 --> 4096 --> 4096 --> 10\n",
    "        self.linear1 = nn.Linear(4608, 4608*2)\n",
    "        self.linear2 = nn.Linear(4608*2,4096)\n",
    "        self.linear3 = nn.Linear(4096, num_class)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        # block 1:         3 x 32 x 32 --> 64 x 16 x 16\n",
    "        x = self.conv1a(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv1b(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # block 2:         64 x 16 x 16 --> 128 x 8 x 8\n",
    "        x = self.conv2a(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2b(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # block 3:         128 x 8 x 8 --> 256 x 4 x 4\n",
    "        x = self.conv3a(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv3b(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        #block 4:          256 x 4 x 4 --> 512 x 2 x 2\n",
    "        x = self.conv4a(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        # linear layers:   512 x 2 x 2 --> 4608 --> 4608*2 --> 4096 --> 10\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 4608)\n",
    "        x = self.linear1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear3(x) \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(X_train, y_train, X_test, y_test):\n",
    "    X_train = torch.from_numpy(np.array(X_train).astype(np.float32))\n",
    "    y_train = torch.from_numpy(np.array(y_train).astype(np.float32)).type(torch.LongTensor)\n",
    "    X_test = torch.from_numpy(np.array(X_test).astype(np.float32))\n",
    "    y_test = torch.from_numpy(np.array(y_test).astype(np.float32)).type(torch.LongTensor)\n",
    "    X_train = X_train.view(-1, 3, 50, 50)\n",
    "    X_test = X_test.view(-1, 3, 50, 50)\n",
    "    \n",
    "    my_lr = 0.02\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    bs = 64\n",
    "    num_class = 6\n",
    "\n",
    "    net = VGG_convnet(3, num_class)\n",
    "    mean = X_train.mean()\n",
    "    std = X_train.std()\n",
    "    num_train_data = X_train.size()[0]\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        # create a new optimizer at the beginning of each epoch: give the current learning rate.   \n",
    "        optimizer=torch.optim.Adam( net.parameters() , lr=my_lr )\n",
    "\n",
    "        # set the running quatities to zero at the beginning of the epoch\n",
    "        running_loss=0\n",
    "        running_error=0\n",
    "        running_acc = 0\n",
    "        num_batches=0\n",
    "\n",
    "        # set the order in which to visit the image from the training set\n",
    "        shuffled_indices = torch.randperm(num_train_data)\n",
    "\n",
    "        for count in range(0,num_train_data,bs):\n",
    "\n",
    "            # Set the gradients to zeros\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # create a minibatch       \n",
    "            indices = shuffled_indices[count:count+bs]\n",
    "            minibatch_data =  X_train[indices]\n",
    "            minibatch_label =  y_train[indices]\n",
    "\n",
    "\n",
    "            # normalize the minibatch (this is the only difference compared to before!)\n",
    "            inputs = (minibatch_data - mean)/std\n",
    "\n",
    "            # tell Pytorch to start tracking all operations that will be done on \"inputs\"\n",
    "            inputs.requires_grad_()\n",
    "\n",
    "            # forward the minibatch through the net \n",
    "            scores=net( inputs ) \n",
    "\n",
    "            # Compute the average of the losses of the data points in the minibatch\n",
    "            loss =  criterion( scores , minibatch_label) \n",
    "\n",
    "            # backward pass to compute dL/dU, dL/dV and dL/dW   \n",
    "            loss.backward()\n",
    "\n",
    "            # do one step of stochastic gradient descent: U=U-lr(dL/dU), V=V-lr(dL/dU), ...\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            # START COMPUTING STATS\n",
    "\n",
    "            # add the loss of this batch to the running loss\n",
    "            running_loss += loss.detach().item()\n",
    "\n",
    "            # compute the error made on this batch and add it to the running error       \n",
    "            error = get_error( scores.detach() , minibatch_label)\n",
    "            acc = get_accuracy(scores.detach() , minibatch_label)\n",
    "            running_error += error.item()\n",
    "            running_acc += acc.item()\n",
    "\n",
    "            num_batches+=1        \n",
    "\n",
    "\n",
    "        # compute stats for the full training set\n",
    "        total_loss = running_loss/num_batches\n",
    "        total_error = running_error/num_batches\n",
    "        total_acc = running_acc/num_batches\n",
    "\n",
    "\n",
    "        print('epoch=',epoch, '\\t loss=', total_loss , '\\t error=', total_error*100 ,'percent')\n",
    "        print('accuracy =', total_acc)\n",
    "        print(' ')\n",
    "\n",
    "    eval_on_test_set(X_test, y_test, net, mean, std, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.73 GiB for an array with shape (6000, 224, 224, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24464/1507065899.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24464/2282301500.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 6.73 GiB for an array with shape (6000, 224, 224, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "train_network(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1427\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24464/475650044.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# X_train, X_test, y_train, y_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# diplay the picture\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# choose a picture at random\n",
    "idx=randint(0, 1500)\n",
    "label = ('Not Skin', 'Normal', 'Pustule', 'Whitehead', 'Blackhead', 'Cyst',)\n",
    "\n",
    "print(idx)\n",
    "im=X[idx]\n",
    "# X_train, X_test, y_train, y_test\n",
    "# diplay the picture\n",
    "image_label = f\"label index: {y[idx]}; label is {label[y[idx]]}\"\n",
    "image_utils().plot_image(im,title=image_label, figsize=(5,5))\n",
    "\n",
    "im = torch.from_numpy(np.array(im).astype(np.float32))\n",
    "X_train_ = torch.from_numpy(np.array(X_train).astype(np.float32))\n",
    "X_train_ = X_train_.view(-1, 3, 50, 50)\n",
    "mean= X_train_.mean()\n",
    "std= X_train_.std()\n",
    "# # send to device, rescale, and view as a batch of 1 \n",
    "# im = im.to(device)\n",
    "im= (im-mean) / std\n",
    "im=im.view(1,3,50,50)\n",
    "\n",
    "# # feed it to the net and display the confidence scores\n",
    "scores =  net(im) \n",
    "probs= torch.softmax(scores, dim=1)\n",
    "image_utils().show_prob_pimples(probs.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(978, 50, 50, 3)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "188299b107256fe873ab79b6089594fb9be85d55d578db9419dca9181f4278ba"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('deeplearn_course': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
