{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from keras.preprocessing.image import load_img \n",
    "from keras.preprocessing.image import img_to_array \n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "# models \n",
    "from keras.applications.vgg16 import VGG16 \n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "\n",
    "# clustering and dimension reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from src.dataLoader import dataLoader\n",
    "from src.utils import image_utils, ismember\n",
    "\n",
    "from src.preprocessing import imadjust,imagecrop,imagePaddingByShape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading full dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataLoader(\"../dataset\")\n",
    "\n",
    "fileNameList = [str(imgIdx)+\".jpg\" for imgIdx in range(1500,3000)]\n",
    "imageFileList = dataset.LoadFileList(fileNameList=fileNameList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtraction():\n",
    "    def __init__(self, imageFileList:list):\n",
    "        self.imageFileList = imageFileList\n",
    "        model = VGG16()\n",
    "        self.model = Model(inputs = model.inputs, outputs = model.layers[-2].output)\n",
    "        self.featureDict = {}\n",
    "        self.fearutesData = np.array([])\n",
    "        self.reducedFeature = np.array([])\n",
    "\n",
    "    def extract_features(self, file, model):\n",
    "        # load the image as a 224x224 array\n",
    "        img = load_img(file, target_size=(224,224))\n",
    "        # convert from 'PIL.Image.Image' to numpy array\n",
    "        img = np.array(img) \n",
    "        # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
    "        reshaped_img = img.reshape(1,224,224,3) \n",
    "        # prepare image for model\n",
    "        imgx = preprocess_input(reshaped_img)\n",
    "        # get the feature vector\n",
    "        features = model.predict(imgx, use_multiprocessing=True)\n",
    "        return features\n",
    "        \n",
    "    def getFullFeature(self):\n",
    "        for image_path in self.imageFileList:\n",
    "            # try to extract the features and update the dictionary\n",
    "            try:\n",
    "                feat = self.extract_features(image_path,self.model)\n",
    "                self.featureDict[image_path] = feat\n",
    "            # if something fails, save the extracted features as a pickle file (optional)\n",
    "            except:\n",
    "                pass\n",
    "        self.imageFileList = np.array(list(self.featureDict.keys()))\n",
    "        # get a list of just the features\n",
    "        self.fearutesData = np.array(list(self.featureDict.values())).reshape(-1,4096)\n",
    "        print(self.fearutesData.shape)\n",
    "        return self.fearutesData\n",
    "\n",
    "    def getReducedFeature(self,n_components:int=100):\n",
    "        pca = PCA(n_components=n_components)\n",
    "        feat = self.getFullFeature()\n",
    "        pca.fit(feat)\n",
    "        self.reducedFeature = pca.transform(feat)\n",
    "        print(f\"Components before PCA: {feat.shape[1]}\")\n",
    "        print(f\"Components after PCA: {pca.n_components}\")\n",
    "\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "        plt.xlabel('number of components')\n",
    "        plt.ylabel('cumulative explained variance');\n",
    "        plt.show()\n",
    "        return self.reducedFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ori_dataset = []\n",
    "\n",
    "# for image_path in imageFileList:\n",
    "#     # get RGB image\n",
    "#     color_image = image_utils().get_image(image_path, image_scale=cv2.COLOR_BGR2RGB, is_gray=False)\n",
    "#     ori_dataset.append(color_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Feature extraction on full dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1st_ReducedFeatures = FeatureExtraction(imageFileList).getReducedFeature(n_components=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clustering():\n",
    "    def __init__(\n",
    "        self, \n",
    "        model, \n",
    "        Data:np.ndarray, \n",
    "        fileLocations:list, \n",
    "        NumCluster:int=5) -> None:\n",
    "        self.model = model\n",
    "        self.Data = Data\n",
    "        self.fileLocations = fileLocations\n",
    "        self.groups = {}\n",
    "        self.NumCluster = NumCluster\n",
    "\n",
    "    def train(self):\n",
    "        # fit the model\n",
    "        self.model.fit(self.Data)\n",
    "        # assign a cluster to each example\n",
    "        yhat = self.model.predict(self.Data)\n",
    "        # holds the cluster id and the images { id: [images] }\n",
    "        for file, cluster in zip(self.fileLocations,yhat):\n",
    "            if cluster not in self.groups.keys():\n",
    "                self.groups[cluster] = []\n",
    "                self.groups[cluster].append(file)\n",
    "            else:\n",
    "                self.groups[cluster].append(file)\n",
    "        return self\n",
    "\n",
    "    def display_cluster(self,no_of_col:int = 10, cluster_idx=None):\n",
    "        start_idx = 0\n",
    "        end_idx = self.NumCluster\n",
    "        if cluster_idx is not None:\n",
    "            start_idx = cluster_idx\n",
    "            end_idx = cluster_idx+1\n",
    "        for i in range(start_idx,end_idx):\n",
    "            filePaths_row = np.array(self.groups[i])\n",
    "            num = filePaths_row.shape[0]\n",
    "            r = np.floor(num/float(no_of_col))\n",
    "\n",
    "            print(\"cluster \"+str(i))\n",
    "            print(str(num)+\" elements\")\n",
    "\n",
    "            plt.figure(figsize=(10,10))\n",
    "            plt.axis('off')\n",
    "            for k in range(0, num):\n",
    "                plt.subplot(r+1, no_of_col, k+1)\n",
    "                image = load_img(filePaths_row[k])\n",
    "                plt.imshow(image, cmap='gray')\n",
    "                plt.title(filePaths_row[k].name, fontsize=8)\n",
    "                plt.axis('off')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumCluster = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# kmeans = Clustering(\n",
    "#     KMeans(n_clusters=NumCluster,init='random'),\n",
    "#     dataset_1st_ReducedFeatures,\n",
    "#     imageFileList,\n",
    "#     NumCluster=NumCluster\n",
    "#     ).train()\n",
    "# kmeans.display_cluster(no_of_col=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "GMM1 = Clustering(\n",
    "    GaussianMixture(n_components=NumCluster,random_state=1),\n",
    "    dataset_1st_ReducedFeatures,\n",
    "    imageFileList,\n",
    "    NumCluster=NumCluster\n",
    "    ).train()\n",
    "\n",
    "GMM1.display_cluster()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageFileList_cluster = GMM1.groups[0]\n",
    "Cluster_ReducedFeatures = FeatureExtraction(imageFileList_cluster).getReducedFeature(n_components=50)\n",
    "\n",
    "NumCluster = 5\n",
    "# GMM2 = Clustering(\n",
    "#     GaussianMixture(n_components=NumCluster,random_state=1),\n",
    "#     Cluster_ReducedFeatures,\n",
    "#     imageFileList_cluster,\n",
    "#     NumCluster=NumCluster\n",
    "#     ).train()\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = Clustering(\n",
    "    KMeans(n_clusters=NumCluster,init='random'),\n",
    "    Cluster_ReducedFeatures,\n",
    "    imageFileList_cluster,\n",
    "    NumCluster=NumCluster\n",
    "    ).train()\n",
    "\n",
    "kmeans.display_cluster(no_of_col=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further extract from intra group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# result_df = pd.DataFrame(imageFileList, columns=[\"file_path\"])\n",
    "# result_df[\"Image File\"] = result_df[\"file_path\"].astype(str).str.split(\"\\\\\").str[-1]\n",
    "# result_df['label'] = 0\n",
    "# result_df['is_label'] = False\n",
    "# result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_label(df, image_idx, label):\n",
    "    file_name = str(image_idx)+\".jpg\"\n",
    "    df.loc[df[\"Image File\"]==file_name, \"label\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_clusters = kmeans.groups[0]\n",
    "label = 0\n",
    "result_df.loc[(result_df.is_label==False) & (result_df.file_path.isin(chosen_clusters)), \"label\"] = label\n",
    "result_df.loc[(result_df.is_label==False) & (result_df.file_path.isin(chosen_clusters)), \"is_label\"] = True\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df.to_csv(\".\\label.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx = 709\n",
    "label = 2\n",
    "modify_label(result_df, image_idx, label)\n",
    "result_df[result_df[\"Image File\"]==f\"{image_idx}.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.display_cluster(no_of_col=5,cluster_idx=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data cleaning\n",
    "# GMM2_group = []\n",
    "# for cluster in GMM1.groups:\n",
    "#     imageFileList_cluster=cluster\n",
    "#     print(len(imageFileList_cluster))\n",
    "#     cluster_size = len(imageFileList_cluster)\n",
    "#     Cluster_ReducedFeatures = FeatureExtraction(imageFileList_cluster).getReducedFeature(n_components=int(cluster_size/5))\n",
    "\n",
    "#     NumCluster = 8\n",
    "#     GMM2 = Clustering(\n",
    "#         GaussianMixture(n_components=NumCluster,random_state=1),\n",
    "#         Cluster_ReducedFeatures,\n",
    "#         imageFileList_cluster,\n",
    "#         NumCluster=NumCluster\n",
    "#         ).train()\n",
    "\n",
    "#     GMM2.display_cluster(no_of_col=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster_ReducedFeatures = FeatureExtraction(imageFileList_cluster)\\\n",
    "#     .getReducedFeature(n_components=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumCluster = 8\n",
    "# GMM2 = Clustering(\n",
    "#     GaussianMixture(n_components=NumCluster,random_state=1),\n",
    "#     Cluster_ReducedFeatures,\n",
    "#     imageFileList_cluster,\n",
    "#     NumCluster=NumCluster\n",
    "#     ).train()\n",
    "\n",
    "# GMM2.display_cluster(no_of_col=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imageFileList_cluster=GMM2.groups[4]\n",
    "# print(len(imageFileList_cluster))\n",
    "\n",
    "# Cluster_ReducedFeatures = FeatureExtraction(imageFileList_cluster)\\\n",
    "#     .getReducedFeature(n_components=10)\n",
    "\n",
    "# NumCluster = 3\n",
    "# GMM3 = Clustering(\n",
    "#     GaussianMixture(n_components=NumCluster,random_state=1),\n",
    "#     Cluster_ReducedFeatures,\n",
    "#     imageFileList_cluster,\n",
    "#     NumCluster=NumCluster\n",
    "#     ).train()\n",
    "\n",
    "# GMM3.display_cluster(no_of_col=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ae59be3bbb3032c82198ddb7a289c47bb75c4ade3eaa25e8c11ba3a93c8e886"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('deeplearn_course': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
